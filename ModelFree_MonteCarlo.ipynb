{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "3-a) Tic-Tac-Toe agent using the MCTS algorithm. The number of Monte Carlo simulations allowed for each board configuration must be configurable"
      ],
      "metadata": {
        "id": "LLiz2MmbSZwt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T3aMJmaBlL8O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self, *operations):\n",
        "        self.operations = operations\n",
        "\n",
        "    def transform(self, target):\n",
        "        for op in self.operations:\n",
        "            target = op.transform(target)\n",
        "        return target\n",
        "\n",
        "    def reverse(self, target):\n",
        "        for op in reverse(self.operations):\n",
        "            target = op.reverse(target)\n",
        "        return target\n",
        "\n",
        "\n",
        "class Identity:\n",
        "    @staticmethod\n",
        "    def transform(matrix2d):\n",
        "        return matrix2d\n",
        "\n",
        "    @staticmethod\n",
        "    def reverse(matrix2d):\n",
        "        return matrix2d\n",
        "\n",
        "\n",
        "class Rotate90:\n",
        "    def __init__(self, number_of_rotations):\n",
        "        self.number_of_rotations = number_of_rotations\n",
        "        self.op = np.rot90\n",
        "\n",
        "    def transform(self, matrix2d):\n",
        "        return self.op(matrix2d, self.number_of_rotations)\n",
        "\n",
        "    def reverse(self, transformed_matrix2d):\n",
        "        return self.op(transformed_matrix2d, -self.number_of_rotations)\n",
        "\n",
        "\n",
        "class Flip:\n",
        "    def __init__(self, op):\n",
        "        self.op = op\n",
        "\n",
        "    def transform(self, matrix2d):\n",
        "        return self.op(matrix2d)\n",
        "\n",
        "    def reverse(self, transformed_matrix2d):\n",
        "        return self.transform(transformed_matrix2d)\n",
        "\n",
        "\n",
        "def reverse(items):\n",
        "    return items[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "TRANSFORMATIONS = [Identity(), Rotate90(1), Rotate90(2), Rotate90(3),\n",
        "                   Flip(np.flipud), Flip(np.fliplr),\n",
        "                   Transform(Rotate90(1), Flip(np.flipud)),\n",
        "                   Transform(Rotate90(1), Flip(np.fliplr))]\n",
        "\n",
        "BOARD_SIZE = 3\n",
        "BOARD_DIMENSIONS = (BOARD_SIZE, BOARD_SIZE)\n",
        "\n",
        "CELL_X = 1\n",
        "CELL_O = -1\n",
        "CELL_EMPTY = 0\n",
        "\n",
        "RESULT_X_WINS = 1\n",
        "RESULT_O_WINS = -1\n",
        "RESULT_DRAW = 0\n",
        "RESULT_NOT_OVER = 2\n",
        "\n",
        "new_board = np.array([CELL_EMPTY] * BOARD_SIZE ** 2)\n",
        "\n",
        "\n",
        "def play_game(x_strategy, o_strategy):\n",
        "    board = Board()\n",
        "    player_strategies = itertools.cycle([x_strategy, o_strategy])\n",
        "\n",
        "    while not board.is_gameover():\n",
        "        play = next(player_strategies)\n",
        "        board = play(board)\n",
        "\n",
        "    return board\n",
        "\n",
        "\n",
        "def play_games(total_games, x_strategy, o_strategy, play_single_game=play_game):\n",
        "    results = {\n",
        "        RESULT_X_WINS: 0,\n",
        "        RESULT_O_WINS: 0,\n",
        "        RESULT_DRAW: 0\n",
        "    }\n",
        "\n",
        "    for g in range(total_games):\n",
        "        end_of_game = (play_single_game(x_strategy, o_strategy))\n",
        "        result = end_of_game.get_game_result()\n",
        "        results[result] += 1\n",
        "\n",
        "    x_wins_percent = results[RESULT_X_WINS] / total_games * 100\n",
        "    o_wins_percent = results[RESULT_O_WINS] / total_games * 100\n",
        "    draw_percent = results[RESULT_DRAW] / total_games * 100\n",
        "\n",
        "    print(f\"x wins: {x_wins_percent:.2f}%\")\n",
        "    print(f\"o wins: {o_wins_percent:.2f}%\")\n",
        "    print(f\"draw  : {draw_percent:.2f}%\")\n",
        "\n",
        "\n",
        "def play_random_move(board):\n",
        "    move = board.get_random_valid_move_index()\n",
        "    return board.play_move(move)\n",
        "\n",
        "\n",
        "def is_even(value):\n",
        "    return value % 2 == 0\n",
        "\n",
        "\n",
        "def is_empty(values):\n",
        "    return values is None or len(values) == 0\n",
        "\n",
        "\n",
        "class Board:\n",
        "    def __init__(self, board=None, illegal_move=None):\n",
        "        if board is None:\n",
        "            self.board = np.copy(new_board)\n",
        "        else:\n",
        "            self.board = board\n",
        "\n",
        "        self.illegal_move = illegal_move\n",
        "\n",
        "        self.board_2d = self.board.reshape(BOARD_DIMENSIONS)\n",
        "\n",
        "    def get_game_result(self):\n",
        "        if self.illegal_move is not None:\n",
        "            return RESULT_O_WINS if self.get_turn() == CELL_X else RESULT_X_WINS\n",
        "\n",
        "        rows_cols_and_diagonals = get_rows_cols_and_diagonals(self.board_2d)\n",
        "\n",
        "        sums = list(map(sum, rows_cols_and_diagonals))\n",
        "        max_value = max(sums)\n",
        "        min_value = min(sums)\n",
        "\n",
        "        if max_value == BOARD_SIZE:\n",
        "            return RESULT_X_WINS\n",
        "\n",
        "        if min_value == -BOARD_SIZE:\n",
        "            return RESULT_O_WINS\n",
        "\n",
        "        if CELL_EMPTY not in self.board_2d:\n",
        "            return RESULT_DRAW\n",
        "\n",
        "        return RESULT_NOT_OVER\n",
        "\n",
        "    def is_gameover(self):\n",
        "        return self.get_game_result() != RESULT_NOT_OVER\n",
        "\n",
        "    def is_in_illegal_state(self):\n",
        "        return self.illegal_move is not None\n",
        "\n",
        "    def play_move(self, move_index):\n",
        "        board_copy = np.copy(self.board)\n",
        "\n",
        "        if move_index not in self.get_valid_move_indexes():\n",
        "            return Board(board_copy, illegal_move=move_index)\n",
        "\n",
        "        board_copy[move_index] = self.get_turn()\n",
        "        return Board(board_copy)\n",
        "\n",
        "    def get_turn(self):\n",
        "        non_zero = np.count_nonzero(self.board)\n",
        "        return CELL_X if is_even(non_zero) else CELL_O\n",
        "\n",
        "    def get_valid_move_indexes(self):\n",
        "        return ([i for i in range(self.board.size)\n",
        "                 if self.board[i] == CELL_EMPTY])\n",
        "\n",
        "    def get_illegal_move_indexes(self):\n",
        "        return ([i for i in range(self.board.size)\n",
        "                if self.board[i] != CELL_EMPTY])\n",
        "\n",
        "    def get_random_valid_move_index(self):\n",
        "        return random.choice(self.get_valid_move_indexes())\n",
        "\n",
        "    def print_board(self):\n",
        "        print(self.get_board_as_string())\n",
        "\n",
        "    def get_board_as_string(self):\n",
        "        rows, cols = self.board_2d.shape\n",
        "        board_as_string = \"-------\\n\"\n",
        "        for r in range(rows):\n",
        "            for c in range(cols):\n",
        "                move = get_symbol(self.board_2d[r, c])\n",
        "                if c == 0:\n",
        "                    board_as_string += f\"|{move}|\"\n",
        "                elif c == 1:\n",
        "                    board_as_string += f\"{move}|\"\n",
        "                else:\n",
        "                    board_as_string += f\"{move}|\\n\"\n",
        "        board_as_string += \"-------\\n\"\n",
        "\n",
        "        return board_as_string\n",
        "\n",
        "\n",
        "class BoardCache:\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "\n",
        "    def set_for_position(self, board, o):\n",
        "        self.cache[board.board_2d.tobytes()] = o\n",
        "\n",
        "    def get_for_position(self, board):\n",
        "        board_2d = board.board_2d\n",
        "\n",
        "        orientations = get_symmetrical_board_orientations(board_2d)\n",
        "\n",
        "        for b, t in orientations:\n",
        "            result = self.cache.get(b.tobytes())\n",
        "            if result is not None:\n",
        "                return (result, t), True\n",
        "\n",
        "        return None, False\n",
        "\n",
        "    def reset(self):\n",
        "        self.cache = {}\n",
        "\n",
        "\n",
        "def get_symmetrical_board_orientations(board_2d):\n",
        "    return [(t.transform(board_2d), t) for t in TRANSFORMATIONS]\n",
        "\n",
        "\n",
        "def get_rows_cols_and_diagonals(board_2d):\n",
        "    rows_and_diagonal = get_rows_and_diagonal(board_2d)\n",
        "    cols_and_antidiagonal = get_rows_and_diagonal(np.rot90(board_2d))\n",
        "    return rows_and_diagonal + cols_and_antidiagonal\n",
        "\n",
        "\n",
        "def get_rows_and_diagonal(board_2d):\n",
        "    num_rows = board_2d.shape[0]\n",
        "    return ([row for row in board_2d[range(num_rows), :]]\n",
        "            + [board_2d.diagonal()])\n",
        "\n",
        "\n",
        "def get_symbol(cell):\n",
        "    if cell == CELL_X:\n",
        "        return 'X'\n",
        "    if cell == CELL_O:\n",
        "        return 'O'\n",
        "    return '-'\n",
        "\n",
        "\n",
        "def is_draw(board):\n",
        "    return board.get_game_result() == RESULT_DRAW"
      ],
      "metadata": {
        "id": "lfzIGpa-caai"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "nodecache = BoardCache()\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.parents = BoardCache()\n",
        "        self.visits = 0\n",
        "        self.wins = 0\n",
        "        self.losses = 0\n",
        "        self.draws = 0\n",
        "\n",
        "    def add_parent_node(self, node_cache, parent_board):\n",
        "        result, found = self.parents.get_for_position(parent_board)\n",
        "        if found is False:\n",
        "            parent_node = find_or_create_node(node_cache, parent_board)\n",
        "            self.parents.set_for_position(parent_board, parent_node)\n",
        "\n",
        "    def get_total_visits_for_parent_nodes(self):\n",
        "        return sum([parent_node.visits for parent_node\n",
        "                    in self.parents.cache.values()])\n",
        "\n",
        "    def value(self):\n",
        "        if self.visits == 0:\n",
        "            return 0\n",
        "\n",
        "        success_percentage = (self.wins + self.draws) / self.visits\n",
        "        return success_percentage\n",
        "\n",
        "\n",
        "def play_game_and_reset_playouts(x_strategy, o_strategy, node_cache=nodecache):\n",
        "    node_cache.reset()\n",
        "    board = play_game(x_strategy, o_strategy)\n",
        "    node_cache.reset()\n",
        "    return board\n",
        "\n",
        "def play_mcts_move_with_live_playouts(board, node_cache=nodecache, num_playouts=200):\n",
        "    perform_training_playouts(node_cache, board, num_playouts,\n",
        "                              display_progress=False)\n",
        "    return play_mcts_move(board, node_cache)\n",
        "\n",
        "def play_mcts_move(board, node_cache=nodecache):\n",
        "    move_index_node_pairs = get_move_index_node_pairs(board, node_cache)\n",
        "    move_index_to_play = max(move_index_node_pairs,\n",
        "                             key=lambda pair: pair[1].value())[0]\n",
        "    return board.play_move(move_index_to_play)\n",
        "\n",
        "\n",
        "def get_move_index_node_pairs(board, node_cache):\n",
        "    boards = [board.play_move(mi) for mi in board.get_valid_move_indexes()]\n",
        "    nodes = [find_or_create_node(node_cache, b) for b in boards]\n",
        "\n",
        "    return zip(board.get_valid_move_indexes(), nodes)\n",
        "\n",
        "\n",
        "def perform_training_playouts(node_cache=nodecache, board=Board(),\n",
        "                              num_playouts=4000, display_progress=True):\n",
        "    for game in range(num_playouts):\n",
        "        perform_game_playout(node_cache, board)\n",
        "        if display_progress is True and (game+1) % (num_playouts / 10) == 0:\n",
        "            print(f\"{game+1}/{num_playouts} playouts...\")\n",
        "\n",
        "\n",
        "def perform_game_playout(node_cache, board):\n",
        "    game_history = [board]\n",
        "\n",
        "    while not board.is_gameover():\n",
        "        move_index = choose_move(node_cache, board)\n",
        "        board = board.play_move(move_index)\n",
        "        game_history.append(board)\n",
        "\n",
        "    backpropagate(node_cache, board, game_history)\n",
        "\n",
        "\n",
        "def choose_move(node_cache, parent_board):\n",
        "    move_value_pairs = calculate_values(node_cache, parent_board)\n",
        "    return max(move_value_pairs, key=lambda pair: pair[1])[0]\n",
        "\n",
        "\n",
        "def calculate_values(node_cache, parent_board):\n",
        "    child_boards = [parent_board.play_move(mi) for mi\n",
        "                    in parent_board.get_valid_move_indexes()]\n",
        "    values = [calculate_value(node_cache, parent_board, cb) for cb\n",
        "              in child_boards]\n",
        "    return zip(parent_board.get_valid_move_indexes(), values)\n",
        "\n",
        "\n",
        "def calculate_value(node_cache, parent_board, board):\n",
        "    node = find_or_create_node(node_cache, board)\n",
        "    node.add_parent_node(node_cache, parent_board)\n",
        "    if node.visits == 0:\n",
        "        return math.inf\n",
        "\n",
        "    parent_node_visits = node.get_total_visits_for_parent_nodes()\n",
        "\n",
        "    assert node.visits <= parent_node_visits, \\\n",
        "        \"child node visits should be a subset of visits to the parent node \"\n",
        "\n",
        "    exploration_term = (math.sqrt(2.0)\n",
        "                        * math.sqrt(math.log(parent_node_visits) / node.visits))\n",
        "\n",
        "    value = node.value() + exploration_term\n",
        "\n",
        "    return value\n",
        "\n",
        "\n",
        "def backpropagate(node_cache, final_board_position, game_history):\n",
        "    for board in game_history:\n",
        "        node = find_node(node_cache, board)\n",
        "        node.visits += 1\n",
        "        if is_win(board.get_turn(), final_board_position):\n",
        "            node.wins += 1\n",
        "        elif is_loss(board.get_turn(), final_board_position):\n",
        "            node.losses += 1\n",
        "        elif is_draw(final_board_position):\n",
        "            node.draws += 1\n",
        "        else:\n",
        "            raise ValueError(\"Illegal game state\")\n",
        "\n",
        "\n",
        "def find_node(node_cache, board):\n",
        "    result, found = node_cache.get_for_position(board)\n",
        "    assert found is True, \"node must exist\"\n",
        "    node, _ = result\n",
        "    return node\n",
        "\n",
        "\n",
        "def find_or_create_node(node_cache, board):\n",
        "    result, found = node_cache.get_for_position(board)\n",
        "    if found is False:\n",
        "        node = Node()\n",
        "        node_cache.set_for_position(board, node)\n",
        "        return node\n",
        "\n",
        "    node, _ = result\n",
        "    return node\n",
        "\n",
        "\n",
        "def is_win(player, board):\n",
        "    result = board.get_game_result()\n",
        "    return ((player == CELL_X and result == RESULT_O_WINS)\n",
        "            or (player == CELL_O and result == RESULT_X_WINS))\n",
        "\n",
        "\n",
        "def is_loss(player, board):\n",
        "    result = board.get_game_result()\n",
        "    return ((player == CELL_X and result == RESULT_X_WINS)\n",
        "            or (player == CELL_O and result == RESULT_O_WINS))"
      ],
      "metadata": {
        "id": "gb1yG3AJcoBj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "ML6IiekueDGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training MCTS...\")\n",
        "perform_training_playouts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-3Sc3pndwep",
        "outputId": "8f157a81-4d01-44cc-e112-dc0168e33966"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MCTS...\n",
            "400/4000 playouts...\n",
            "800/4000 playouts...\n",
            "1200/4000 playouts...\n",
            "1600/4000 playouts...\n",
            "2000/4000 playouts...\n",
            "2400/4000 playouts...\n",
            "2800/4000 playouts...\n",
            "3200/4000 playouts...\n",
            "3600/4000 playouts...\n",
            "4000/4000 playouts...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3-b) Test the efficacy of the MCTS agent by soliciting move recommendations for the following board configurations\n",
        "\n",
        "• A suitable board configuration in which the MCTS agent is one move away from win\n",
        "\n",
        "**Soln:** when the # of simulations is less than 100, the MCTS agent lost everytime. Only when the agent was trained for more than 1000 simulations, MCTS was winning the last move\n",
        "\n",
        "• A suitable board configuration in which the MCTS agent is one move away from loss\n",
        "\n",
        "**Soln:** when the # of simulations is less than 100, the MCTS agent lost everytime. Only when the agent was trained for more than 1000 simulations, MCTS was winning the last move\n",
        "\n",
        "• The board configuration where the opponent has made the first move and has occupied the centre square\n",
        "\n",
        "**Soln:** when the # of simulations is less than 100 and when opponent took centre square, MCTS lost all the time. After increasing the simulations to 1000, MCTS draws the match all the time."
      ],
      "metadata": {
        "id": "pPB_x1_vSqj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-c) Record the number of wins, loss and draws for Random agents"
      ],
      "metadata": {
        "id": "dz8Ue1EZU3Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\")\n",
        "print(\"Playing random vs MCTS:\")\n",
        "print(\"-----------------------\")\n",
        "play_games(1000, play_random_move, play_mcts_move)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INMB9P2reCbj",
        "outputId": "08e872f5-a028-4b27-9088-31a48cc222a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Playing random vs MCTS:\n",
            "-----------------------\n",
            "x wins: 0.00%\n",
            "o wins: 60.60%\n",
            "draw  : 39.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statistics as stats\n",
        "import random\n",
        "import operator\n",
        "import itertools\n",
        "from collections import deque\n",
        "\n",
        "WIN_VALUE = 1.0\n",
        "DRAW_VALUE = 1.0\n",
        "LOSS_VALUE = 0.0\n",
        "\n",
        "INITIAL_Q_VALUES_FOR_X = 0.0\n",
        "INITIAL_Q_VALUES_FOR_O = 0.0\n",
        "\n",
        "\n",
        "class QTable:\n",
        "    def __init__(self):\n",
        "        self.qtable = BoardCache()\n",
        "\n",
        "    def get_q_values(self, board):\n",
        "        move_indexes = board.get_valid_move_indexes()\n",
        "        qvalues = [self.get_q_value(board, mi) for mi\n",
        "                   in board.get_valid_move_indexes()]\n",
        "\n",
        "        return dict(zip(move_indexes, qvalues))\n",
        "\n",
        "    def get_q_value(self, board, move_index):\n",
        "        new_position = board.play_move(move_index)\n",
        "        result, found = self.qtable.get_for_position(new_position)\n",
        "        if found is True:\n",
        "            qvalue, _ = result\n",
        "            return qvalue\n",
        "\n",
        "        return get_initial_q_value(new_position)\n",
        "\n",
        "    def update_q_value(self, board, move_index, qvalue):\n",
        "        new_position = board.play_move(move_index)\n",
        "\n",
        "        result, found = self.qtable.get_for_position(new_position)\n",
        "        if found is True:\n",
        "            _, t = result\n",
        "            new_position_transformed = Board(\n",
        "                t.transform(new_position.board_2d).flatten())\n",
        "            self.qtable.set_for_position(new_position_transformed, qvalue)\n",
        "            return\n",
        "\n",
        "        self.qtable.set_for_position(new_position, qvalue)\n",
        "\n",
        "    def get_move_index_and_max_q_value(self, board):\n",
        "        q_values = self.get_q_values(board)\n",
        "        return max(q_values.items(), key=operator.itemgetter(1))\n",
        "\n",
        "    def print_q_values(self):\n",
        "        print(f\"num q_values = {len(self.qtable.cache)}\")\n",
        "        for k, v in self.qtable.cache.items():\n",
        "            b = np.frombuffer(k, dtype=int)\n",
        "            board = Board(b)\n",
        "            board.print_board()\n",
        "            print(f\"qvalue = {v}\")\n",
        "\n",
        "\n",
        "def get_initial_q_value(board):\n",
        "    return (INITIAL_Q_VALUES_FOR_X if board.get_turn() == CELL_O\n",
        "            else INITIAL_Q_VALUES_FOR_O)\n",
        "\n",
        "\n",
        "qtables = [QTable()]\n",
        "\n",
        "double_qtables = [QTable(), QTable()]\n",
        "\n",
        "\n",
        "def create_q_table_player(q_tables):\n",
        "    def play(board):\n",
        "        return play_q_table_move(board, q_tables)\n",
        "\n",
        "    return play\n",
        "\n",
        "\n",
        "def play_q_table_move(board, q_tables=None):\n",
        "    if q_tables is None:\n",
        "        q_tables = qtables\n",
        "\n",
        "    move_index = choose_move_index(q_tables, board, 0)\n",
        "    return board.play_move(move_index)\n",
        "\n",
        "\n",
        "def choose_move_index(q_tables, board, epsilon):\n",
        "    if epsilon > 0:\n",
        "        random_value_from_0_to_1 = np.random.uniform()\n",
        "        if random_value_from_0_to_1 < epsilon:\n",
        "            return board.get_random_valid_move_index()\n",
        "\n",
        "    move_q_value_pairs = get_move_average_q_value_pairs(q_tables, board)\n",
        "\n",
        "    return max(move_q_value_pairs, key=lambda pair: pair[1])[0]\n",
        "\n",
        "\n",
        "def get_move_average_q_value_pairs(q_tables, board):\n",
        "    move_indexes = sorted(q_tables[0].get_q_values(board).keys())\n",
        "\n",
        "    avg_q_values = [stats.mean(gather_q_values_for_move(q_tables, board, mi))\n",
        "                    for mi in move_indexes]\n",
        "\n",
        "    return list(zip(move_indexes, avg_q_values))\n",
        "\n",
        "\n",
        "def gather_q_values_for_move(q_tables, board, move_index):\n",
        "    return [q_table.get_q_value(board, move_index) for q_table in q_tables]\n",
        "\n",
        "\n",
        "def play_training_games_x(total_games=7000, q_tables=None,\n",
        "                          learning_rate=0.4, discount_factor=1.0, epsilon=0.7,\n",
        "                          o_strategies=None):\n",
        "    if q_tables is None:\n",
        "        q_tables = qtables\n",
        "    if o_strategies is None:\n",
        "        o_strategies = [play_random_move]\n",
        "\n",
        "    play_training_games(total_games, q_tables, CELL_X, learning_rate,\n",
        "                        discount_factor, epsilon, None, o_strategies)\n",
        "\n",
        "\n",
        "def play_training_games_o(total_games=7000, q_tables=None,\n",
        "                          learning_rate=0.4, discount_factor=1.0, epsilon=0.7,\n",
        "                          x_strategies=None):\n",
        "    if q_tables is None:\n",
        "        q_tables = qtables\n",
        "    if x_strategies is None:\n",
        "        x_strategies = [play_random_move]\n",
        "\n",
        "    play_training_games(total_games, q_tables, CELL_O, learning_rate,\n",
        "                        discount_factor, epsilon, x_strategies, None)\n",
        "\n",
        "\n",
        "def play_training_games(total_games, q_tables, q_table_player, learning_rate,\n",
        "                        discount_factor, epsilon, x_strategies, o_strategies):\n",
        "    if x_strategies:\n",
        "        x_strategies_to_use = itertools.cycle(x_strategies)\n",
        "\n",
        "    if o_strategies:\n",
        "        o_strategies_to_use = itertools.cycle(o_strategies)\n",
        "\n",
        "    for game in range(total_games):\n",
        "        move_history = deque()\n",
        "\n",
        "        if not x_strategies:\n",
        "            x = [create_training_player(q_tables, move_history, epsilon)]\n",
        "            x_strategies_to_use = itertools.cycle(x)\n",
        "\n",
        "        if not o_strategies:\n",
        "            o = [create_training_player(q_tables, move_history, epsilon)]\n",
        "            o_strategies_to_use = itertools.cycle(o)\n",
        "\n",
        "        x_strategy_to_use = next(x_strategies_to_use)\n",
        "        o_strategy_to_use = next(o_strategies_to_use)\n",
        "\n",
        "        play_training_game(q_tables, move_history, q_table_player,\n",
        "                           x_strategy_to_use, o_strategy_to_use, learning_rate,\n",
        "                           discount_factor)\n",
        "\n",
        "        if (game+1) % (total_games / 10) == 0:\n",
        "            epsilon = max(0, epsilon - 0.1)\n",
        "            print(f\"{game+1}/{total_games} games, using epsilon={epsilon}...\")\n",
        "\n",
        "\n",
        "def play_training_game(q_tables, move_history, q_table_player, x_strategy,\n",
        "                       o_strategy, learning_rate, discount_factor):\n",
        "    board = play_game(x_strategy, o_strategy)\n",
        "\n",
        "    update_training_gameover(q_tables, move_history, q_table_player, board,\n",
        "                             learning_rate, discount_factor)\n",
        "\n",
        "\n",
        "def update_training_gameover(q_tables, move_history, q_table_player, board,\n",
        "                             learning_rate, discount_factor):\n",
        "    game_result_reward = get_game_result_value(q_table_player, board)\n",
        "\n",
        "    # move history is in reverse-chronological order - last to first\n",
        "    next_position, move_index = move_history[0]\n",
        "    for q_table in q_tables:\n",
        "        current_q_value = q_table.get_q_value(next_position, move_index)\n",
        "        new_q_value = calculate_new_q_value(current_q_value, game_result_reward,\n",
        "                                            0.0, learning_rate, discount_factor)\n",
        "\n",
        "        q_table.update_q_value(next_position, move_index, new_q_value)\n",
        "\n",
        "    for (position, move_index) in list(move_history)[1:]:\n",
        "        current_q_table, next_q_table = get_shuffled_q_tables(q_tables)\n",
        "\n",
        "        max_next_move_index, _ = current_q_table.get_move_index_and_max_q_value(\n",
        "            next_position)\n",
        "\n",
        "        max_next_q_value = next_q_table.get_q_value(next_position,\n",
        "                                                    max_next_move_index)\n",
        "\n",
        "        current_q_value = current_q_table.get_q_value(position, move_index)\n",
        "        new_q_value = calculate_new_q_value(current_q_value, 0.0,\n",
        "                                            max_next_q_value, learning_rate,\n",
        "                                            discount_factor)\n",
        "        current_q_table.update_q_value(position, move_index, new_q_value)\n",
        "\n",
        "        next_position = position\n",
        "\n",
        "\n",
        "def calculate_new_q_value(current_q_value, reward, max_next_q_value,\n",
        "                          learning_rate, discount_factor):\n",
        "    weighted_prior_values = (1 - learning_rate) * current_q_value\n",
        "    weighted_new_value = (learning_rate\n",
        "                          * (reward + discount_factor * max_next_q_value))\n",
        "    return weighted_prior_values + weighted_new_value\n",
        "\n",
        "\n",
        "def get_shuffled_q_tables(q_tables):\n",
        "    q_tables_copy = q_tables.copy()\n",
        "    random.shuffle(q_tables_copy)\n",
        "    q_tables_cycle = itertools.cycle(q_tables_copy)\n",
        "\n",
        "    current_q_table = next(q_tables_cycle)\n",
        "    next_q_table = next(q_tables_cycle)\n",
        "\n",
        "    return current_q_table, next_q_table\n",
        "\n",
        "\n",
        "def create_training_player(q_tables, move_history, epsilon):\n",
        "    def play(board):\n",
        "        move_index = choose_move_index(q_tables, board, epsilon)\n",
        "        move_history.appendleft((board, move_index))\n",
        "        return board.play_move(move_index)\n",
        "\n",
        "    return play\n",
        "\n",
        "\n",
        "def get_game_result_value(player, board):\n",
        "    if is_win(player, board):\n",
        "        return WIN_VALUE\n",
        "    if is_loss(player, board):\n",
        "        return LOSS_VALUE\n",
        "    if is_draw(board):\n",
        "        return DRAW_VALUE\n",
        "\n",
        "\n",
        "def is_win(player, board):\n",
        "    result = board.get_game_result()\n",
        "    return ((player == CELL_O and result == RESULT_O_WINS)\n",
        "            or (player == CELL_X and result == RESULT_X_WINS))\n",
        "\n",
        "\n",
        "def is_loss(player, board):\n",
        "    result = board.get_game_result()\n",
        "    return ((player == CELL_O and result == RESULT_X_WINS)\n",
        "            or (player == CELL_X and result == RESULT_O_WINS))\n",
        "\n"
      ],
      "metadata": {
        "id": "AFmdS4CxfFKC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-c) Record the number of wins, loss and draws for Safe (QTable) agents"
      ],
      "metadata": {
        "id": "c1e8Zpc4Ugnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-------------------------\")\n",
        "play_games(1000, play_q_table_move, play_mcts_move)\n",
        "print(\"\")\n",
        "print(\"Playing qtable vs MCTS:\")\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC_2KgAKf9un",
        "outputId": "47ce568e-c9dd-4c28-8a8a-9ab97f434cfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "x wins: 0.00%\n",
            "o wins: 100.00%\n",
            "draw  : 0.00%\n",
            "\n",
            "Playing qtable vs MCTS:\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-d) Record of the number of wins, loss and draws by letting the MCTS agent play 1000 games against itself"
      ],
      "metadata": {
        "id": "be48W0NIVIPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")\n",
        "print(\"Playing MCTS vs MCTS:\")\n",
        "print(\"---------------------\")\n",
        "play_games(1000, play_mcts_move, play_mcts_move)\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5D6-K_KeItv",
        "outputId": "9fe37b92-205b-4195-8da0-15284f1810a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Playing MCTS vs MCTS:\n",
            "---------------------\n",
            "x wins: 0.00%\n",
            "o wins: 0.00%\n",
            "draw  : 100.00%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}